{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asume que los datos estan en ../data/<año>.csv.bz2\n",
    "# fixme: poner el directorio de data que esté en el repo cuando pusheen los pibes\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import fnmatch\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "#sns.set(color_codes=True)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "import numpy as np\n",
    "from cml import normal_equations_solver as nes\n",
    "import math\n",
    "\n",
    "# load data\n",
    "tmp_dir = \"./tmp_csv/\"\n",
    "years = [str(year) for year in range(1994,2009)]\n",
    "#years = [str(year) for year in range(1994,2005)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para jugar con fases\n",
    "\n",
    "time        = np.arange(0, 12, 0.1);\n",
    "amplitude   = np.sin(2 * math.pi / 1* time + math.pi)\n",
    "plt.plot(time, amplitude)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nrmse(pred,y):\n",
    "    return math.sqrt(mean_squared_error(pred, y)) / (y.max()-y.min())\n",
    "\n",
    "max_grade = 0\n",
    "phases = [i*math.pi/2 for i in range(4)]\n",
    "monthly_freqs =  [3, 4, 6, 12]\n",
    "# semanas, meses, bimestres, trimestres, cuatrimestres, semestres, años\n",
    "daily_freqs =  [7] + [355/i for i in [12, 6, 4, 3, 2, 1]] \n",
    "\n",
    "class lsqPredictor:\n",
    "    def __init__(self, phases, freqs, max_grade):\n",
    "        self.phases = phases\n",
    "        self.freqs = freqs\n",
    "        self.max_grade = max_grade\n",
    "    \n",
    "    def trig_vals(self, t):\n",
    "        return  [math.sin(2 * math.pi / f * t + p) for f in self.freqs for p in self.phases]\n",
    "\n",
    "    def get_x_vals(self, x):\n",
    "        x_vals = []\n",
    "        for i in range(len(x)):\n",
    "            row = np.array([i**p for p in range(self.max_grade+1)] + self.trig_vals(i), dtype='float')\n",
    "            x_vals.append(row)\n",
    "        return x_vals\n",
    "    \n",
    "    def print_coefs(self):\n",
    "        c = 0\n",
    "        for i in range(self.max_grade+1):\n",
    "            print(\"Coef de x^{}:\\n{}\".format(i, self.coefs[c]))\n",
    "            c += 1\n",
    "        for i in self.freqs:\n",
    "            for j in self.phases:\n",
    "                print(\"Coef de sinusoide con frecuencia {} y fase {}:\\n{}\".format(i, j, self.coefs[c]))\n",
    "                c += 1\n",
    "                \n",
    "    def fit(self, train_set):\n",
    "        arrays = self.get_x_vals(train_set)\n",
    "        A = np.stack(arrays)\n",
    "        #self.coefs = np.linalg.solve(A.T@A, A.T@train_set)\n",
    "        self.coefs = nes.lstsq(A, train_set)\n",
    "    \n",
    "    def pred(self, pred_set):\n",
    "        arrays = self.get_x_vals(pred_set)\n",
    "        full_A = np.stack(arrays)        \n",
    "        return full_A@self.coefs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df(df1, df2, train_limit_axis, unit_str, sparse_plot=True):\n",
    "    plt.figure(figsize=(16,5))\n",
    "    plt.xlabel('Predicción para el i-ésimo {}'.format(unit_str), fontsize=15)\n",
    "    plt.ylabel('Delay promedio (mins)'.format(unit_str), fontsize=15)\n",
    "    \n",
    "    if sparse_plot:\n",
    "        df2 = df2[df2.index % 20 == 0] \n",
    "        df1 = df1[df1.index % 20 == 0] \n",
    "    \n",
    "    ax1 = df1.dl_pred.plot(color='orange', grid=True, label='pred delay', legend=\"pred\")\n",
    "    df2.ArrDelay.plot(color='blue', grid=True, secondary_y=False, label='real delay', ax=ax1, legend=\"delay\")\n",
    "\n",
    "    xticks = ax1.xaxis.get_major_ticks()\n",
    "    plt.axvline(x=train_limit_axis, color=\"green\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validación cruzada y gráficos\n",
    "def cross_val_delays(filename, freqs, unit_name, sparse_plot=False, n=4):\n",
    "    for trim in [\"full\", \"cut\"]:\n",
    "        print(\"\\n\\n------Trim de outliers: {}------------------------------------\".format(trim))\n",
    "        df = pd.read_csv(tmp_dir+\"{}/{}.csv\".format(filename, trim))\n",
    "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "        df.sort_values(by=\"date\")\n",
    "\n",
    "        tscv = TimeSeriesSplit(n_splits=n)\n",
    "        df_full = pd.read_csv(tmp_dir+\"{}/full.csv\".format(filename))\n",
    "        df_full['date'] = pd.to_datetime(df_full['date'], errors='coerce')\n",
    "        \n",
    "        #si recortamos alguna fecha por outliers la sacamos de df_full tambien para comparar\n",
    "        if trim == \"cut\":\n",
    "            df_full = df_full.loc[df_full[\"date\"].isin(df.date)]\n",
    "            \n",
    "        for train_index, test_index in tscv.split(df):\n",
    "            delays_train, delays_test = df.iloc[train_index][\"ArrDelay\"], df.iloc[test_index][\"ArrDelay\"]\n",
    "            lpr = lsqPredictor(phases, freqs, max_grade)\n",
    "            lpr.fit(delays_train)\n",
    "            \n",
    "            #descomentar para ver coeficientes -----------\n",
    "            #lpr.print_coefs()\n",
    "            train_test_delays = df[\"ArrDelay\"]\n",
    "\n",
    "            df2 = df\n",
    "            day_train_limit = df2.iloc[len(delays_train)][\"date\"]\n",
    "\n",
    "            print(\"Entrena hasta la fecha: {}\".format(day_train_limit))\n",
    "            df2[\"dl_pred\"] = lpr.pred(train_test_delays) \n",
    "            plot_df(df2, df_full, len(delays_train), unit_name, sparse_plot)\n",
    "            \n",
    "            error = nrmse(\n",
    "                df2.loc[df[\"date\"].dt.date > day_train_limit].dl_pred, \n",
    "                df_full.loc[df_full[\"date\"].dt.date > day_train_limit].ArrDelay\n",
    "            )\n",
    "\n",
    "            print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear directorio con data de delays agrupada por retraso \n",
    "\n",
    "# frequency = 'D' (diario) o 'M' (mensual)\n",
    "def create_grouped_files(subdir, years, frequency):\n",
    "    if not os.path.exists(tmp_dir):\n",
    "        os.makedirs(tmp_dir)\n",
    "\n",
    "    if not os.path.exists(tmp_dir + subdir):\n",
    "        os.makedirs(tmp_dir + subdir)\n",
    "    else: \n",
    "        return\n",
    "    \n",
    "    df_cut = pd.DataFrame(columns=[\"date\", \"ArrDelay\"]).set_index(\"date\")\n",
    "    df_full = pd.DataFrame(columns=[\"date\", \"ArrDelay\"]).set_index(\"date\")\n",
    "    for year in years:\n",
    "        if not os.path.exists(tmp_dir+subdir+year+\".csv\"):\n",
    "            print(\"Leyendo csv: {}\".format(year))\n",
    "            df = pd.read_csv(\"../data/\"+year+\".csv.bz2\", compression=\"bz2\", \\\n",
    "                             usecols=[\"Month\", \"Year\", \"DayofMonth\", \"DayOfWeek\", \"ArrDelay\"], \\\n",
    "                             encoding=\"ISO 8859-1\")    \n",
    "        \n",
    "            #formato mas feliz para fechas\n",
    "            dates = pd.to_datetime(df.Year*10000+df.Month*100+df.DayofMonth, format='%Y%m%d')\n",
    "            df[\"date\"] = dates\n",
    "            \n",
    "            #acumulamos en full antes de recortar outliers\n",
    "            df = df[[\"date\", \"ArrDelay\"]]\n",
    "            \n",
    "            dg = df.groupby(pd.Grouper(key='date', freq=frequency)).mean()\n",
    "            df_full = pd.concat([df_full, dg], sort=False)\n",
    "            \n",
    "            #sacamos outliers, nos quedamos con la mitad de los delays por bucket\n",
    "            low = 0.1\n",
    "            high = 0.9\n",
    "            qiles = df.groupby(pd.Grouper(key='date', freq=frequency))[\"ArrDelay\"].quantile([low, high]).unstack(level=1)\n",
    "            mask =  (qiles.loc[df.date, low] < df.ArrDelay.values) & \\\n",
    "                    (df.ArrDelay.values < qiles.loc[df.date, high])\n",
    "            df = df.loc[mask.values]\n",
    "\n",
    "            #agrupamos\n",
    "            df = df.groupby(by=df['date'].dt.date).mean()\n",
    "            \n",
    "            df.to_csv(tmp_dir+subdir+year+\".csv\")\n",
    "            df_cut = pd.concat([df_cut, df], sort=False)\n",
    "            del df \n",
    "            \n",
    "    df_cut.to_csv(tmp_dir+subdir+\"cut\"+\".csv\")\n",
    "    df_full.to_csv(tmp_dir+subdir+\"full\"+\".csv\")\n",
    "\n",
    "create_grouped_files(\"daily/\", years, 'D')\n",
    "print(\"Listo ./tmp_csv/daily/\")\n",
    "create_grouped_files(\"monthly/\", years, 'M')\n",
    "print(\"Listo ./tmp_csv/monthly/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in sorted(os.listdir(tmp_dir+\"monthly/\")):\n",
    "    if filename.endswith(\".csv\") and filename not in [\"cut.csv\", \"full.csv\"]: \n",
    "        print(filename)\n",
    "        df = pd.read_csv(tmp_dir+\"monthly/\"+filename)\n",
    "        fig, ax = plt.subplots(figsize=(16,4))\n",
    "        sns.lineplot(x=df.date, y=df.ArrDelay, linestyle='-')\n",
    "        plt.xticks(plt.xticks()[0], df.date, rotation=90)\n",
    "        plt.tight_layout()\n",
    "        xticks = ax.xaxis.get_major_ticks()\n",
    "        for i in range(len(xticks)):\n",
    "            \"\"\"\n",
    "            if i%1 != 0:\n",
    "                xticks[i].set_visible(True)            \n",
    "            \"\"\"\n",
    "            if i%int((len(xticks))/4) == 0:    \n",
    "                plt.axvline(x=i, color=\"orange\")\n",
    "            if i%int((len(xticks))/3) == 0:    \n",
    "                plt.axvline(x=i, color=\"green\")\n",
    "        fig.autofmt_xdate()\n",
    "        plt.show()\n",
    "        \n",
    "#Trimestres en verde, cuatrimestres en naranja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_cut = pd.read_csv(tmp_dir+\"daily/cut.csv\")\n",
    "print(df_daily_cut)\n",
    "df_daily_cut.plot(x=\"date\", y=\"ArrDelay\", linestyle='-', figsize=(16,4), title = \"acumulado diario sin outliers\")\n",
    "\n",
    "df_daily_full = pd.read_csv(tmp_dir+\"daily/full.csv\")\n",
    "df_daily_full.plot(x=\"date\", y=\"ArrDelay\", linestyle='-', figsize=(16,4), title = \"acumulado diario con outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly_cut = pd.read_csv(tmp_dir+\"monthly/cut.csv\")\n",
    "df_monthly_cut.plot(x=\"date\", y=\"ArrDelay\", linestyle='-', figsize=(16,4), title = \"acumulado mensual sin outliers\")\n",
    "\n",
    "df_monthly_full = pd.read_csv(tmp_dir+\"monthly/full.csv\")\n",
    "df_monthly_full.plot(x=\"date\", y=\"ArrDelay\", linestyle='-', figsize=(16,4), title = \"acumulado mensual con outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de delays\n",
    "## Diario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_grade = 1\n",
    "\n",
    "cross_val_delays(\"daily\", daily_freqs, \"dia\", True, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mensual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del df\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_grade = 1\n",
    "\n",
    "cross_val_delays(\"monthly\", monthly_freqs, \"mes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BORRAR ARCHIVOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#borrar aux de años\n",
    "for filename in os.listdir(tmp_dir):\n",
    "    if fnmatch.fnmatch(filename, '*.csv') and filename != \"merged.csv\":\n",
    "        os.remove(tmp_dir+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#borrar merged\n",
    "os.remove(tmp_dir+\"merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#borrar tmp\n",
    "shutil.rmtree(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
