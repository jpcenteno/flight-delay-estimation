{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asume que los datos estan en ../data/<año>.csv.bz2\n",
    "# fixme: poner el directorio de data que esté en el repo cuando pusheen los pibes\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import fnmatch\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "#sns.set(color_codes=True)\n",
    "\n",
    "# load data\n",
    "tmp_dir = \"./tmp_csv/\"\n",
    "years = [str(year) for year in range(1994,2009)]\n",
    "#years = [str(year) for year in range(1994,2005)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear directorio con data de delays agrupada por retraso \n",
    "\n",
    "# frequency = 'D' (diario) o 'M' (mensual)\n",
    "def create_grouped_files(subdir, years, frequency):\n",
    "    if not os.path.exists(tmp_dir):\n",
    "        os.makedirs(tmp_dir)\n",
    "\n",
    "    if not os.path.exists(tmp_dir + subdir):\n",
    "        os.makedirs(tmp_dir + subdir)\n",
    "    else: \n",
    "        return\n",
    "    \n",
    "    df_cut = pd.DataFrame(columns=[\"date\", \"ArrDelay\"]).set_index(\"date\")\n",
    "    df_full = pd.DataFrame(columns=[\"date\", \"ArrDelay\"]).set_index(\"date\")\n",
    "    for year in years:\n",
    "        if not os.path.exists(tmp_dir+subdir+year+\".csv\"):\n",
    "            print(\"Leyendo csv: {}\".format(year))\n",
    "            df = pd.read_csv(\"../data/\"+year+\".csv.bz2\", compression=\"bz2\", \\\n",
    "                             usecols=[\"Month\", \"Year\", \"DayofMonth\", \"DayOfWeek\", \"ArrDelay\"], \\\n",
    "                             encoding=\"ISO 8859-1\")    \n",
    "        \n",
    "            #formato mas feliz para fechas\n",
    "            dates = pd.to_datetime(df.Year*10000+df.Month*100+df.DayofMonth, format='%Y%m%d')\n",
    "            df[\"date\"] = dates\n",
    "            \n",
    "            #acumulamos en full antes de recortar outliers\n",
    "            df = df[[\"date\", \"ArrDelay\"]]\n",
    "            \n",
    "            dg = df.groupby(pd.Grouper(key='date', freq=frequency)).mean()\n",
    "            df_full = pd.concat([df_full, dg], sort=False)\n",
    "            \n",
    "            #sacamos outliers, nos quedamos con la mitad de los delays por bucket\n",
    "            low = 0.1\n",
    "            high = 0.9\n",
    "            qiles = df.groupby(pd.Grouper(key='date', freq=frequency))[\"ArrDelay\"].quantile([low, high]).unstack(level=1)\n",
    "            mask =  (qiles.loc[df.date, low] < df.ArrDelay.values) & \\\n",
    "                    (df.ArrDelay.values < qiles.loc[df.date, high])\n",
    "            df = df.loc[mask.values]\n",
    "\n",
    "            #agrupamos\n",
    "            df = df.groupby(by=df['date'].dt.date).mean()\n",
    "            \n",
    "            df.to_csv(tmp_dir+subdir+year+\".csv\")\n",
    "            df_cut = pd.concat([df_cut, df], sort=False)\n",
    "            del df \n",
    "            \n",
    "    df_cut.to_csv(tmp_dir+subdir+\"cut\"+\".csv\")\n",
    "    df_full.to_csv(tmp_dir+subdir+\"full\"+\".csv\")\n",
    "\n",
    "create_grouped_files(\"daily/\", years, 'D')\n",
    "print(\"Listo ./tmp_csv/daily/\")\n",
    "create_grouped_files(\"monthly/\", years, 'M')\n",
    "print(\"Listo ./tmp_csv/monthly/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in sorted(os.listdir(tmp_dir+\"monthly/\")):\n",
    "    if filename.endswith(\".csv\") and filename not in [\"cut.csv\", \"full.csv\"]: \n",
    "        print(filename)\n",
    "        df = pd.read_csv(tmp_dir+\"monthly/\"+filename)\n",
    "        fig, ax = plt.subplots(figsize=(16,4))\n",
    "        sns.lineplot(x=df.date, y=df.ArrDelay, linestyle='-')\n",
    "        plt.xticks(plt.xticks()[0], df.date, rotation=90)\n",
    "        plt.tight_layout()\n",
    "        xticks = ax.xaxis.get_major_ticks()\n",
    "        for i in range(len(xticks)):\n",
    "            \"\"\"\n",
    "            if i%1 != 0:\n",
    "                xticks[i].set_visible(True)            \n",
    "            \"\"\"\n",
    "            if i%int((len(xticks))/4) == 0:    \n",
    "                plt.axvline(x=i, color=\"orange\")\n",
    "            if i%int((len(xticks))/3) == 0:    \n",
    "                plt.axvline(x=i, color=\"green\")\n",
    "        fig.autofmt_xdate()\n",
    "        plt.show()\n",
    "        \n",
    "#Trimestres en verde, cuatrimestres en naranja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_cut = pd.read_csv(tmp_dir+\"daily/cut.csv\")\n",
    "print(df_daily_cut)\n",
    "df_daily_cut.plot(x=\"date\", y=\"ArrDelay\", linestyle='-', figsize=(16,4), title = \"acumulado diario sin outliers\")\n",
    "\n",
    "df_daily_full = pd.read_csv(tmp_dir+\"daily/full.csv\")\n",
    "df_daily_full.plot(x=\"date\", y=\"ArrDelay\", linestyle='-', figsize=(16,4), title = \"acumulado diario con outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly_cut = pd.read_csv(tmp_dir+\"monthly/cut.csv\")\n",
    "df_monthly_cut.plot(x=\"date\", y=\"ArrDelay\", linestyle='-', figsize=(16,4), title = \"acumulado mensual sin outliers\")\n",
    "\n",
    "df_monthly_full = pd.read_csv(tmp_dir+\"monthly/full.csv\")\n",
    "df_monthly_full.plot(x=\"date\", y=\"ArrDelay\", linestyle='-', figsize=(16,4), title = \"acumulado mensual con outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CML acá \n",
    "## Diario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "df = pd.read_csv(tmp_dir+\"daily/full.csv\")\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "df.sort_values(by=\"date\")\n",
    "\n",
    "year_train_limit = 2007\n",
    "lower_year_train_limit = 1994\n",
    "\n",
    "train_delays = df.loc[(df[\"date\"].dt.year < year_train_limit) & \\\n",
    "                      (df[\"date\"].dt.year > lower_year_train_limit)][\"ArrDelay\"]\n",
    "print(len(train_delays))\n",
    "print(len(df[\"ArrDelay\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para jugar con fases\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "time        = np.arange(0, 12, 0.1);\n",
    "amplitude   = np.sin(2 * math.pi / 1* time + math.pi)\n",
    "plt.plot(time, amplitude)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_grade = 1\n",
    "phases = [i*math.pi/2 for i in range(4)]\n",
    "monthly_freqs =  [3, 4, 6, 12]\n",
    "# semanas, meses, bimestres, trimestres, cuatrimestres, semestres, años\n",
    "daily_freqs =  [7] + [355/i for i in [12, 6, 4, 3, 2, 1]] \n",
    "\n",
    "class lsqPredictor:\n",
    "    def __init__(self, phases, freqs, max_grade):\n",
    "        self.phases = phases\n",
    "        self.freqs = freqs\n",
    "        self.max_grade = max_grade\n",
    "    \n",
    "    def trig_vals(self, t):\n",
    "        return  [math.sin(2 * math.pi / f * t + p) for f in self.freqs for p in self.phases]\n",
    "\n",
    "    def get_x_vals(self, x):\n",
    "        x_vals = []\n",
    "        for i in range(len(x)):\n",
    "            row = np.array([i**p for p in range(self.max_grade+1)] + self.trig_vals(i), dtype='float')\n",
    "            x_vals.append(row)\n",
    "        return x_vals\n",
    "    \n",
    "    def print_coefs(self):\n",
    "        c = 0\n",
    "        for i in range(self.max_grade+1):\n",
    "            print(\"Coef de x^{}:\\n{}\".format(i, self.coefs[c]))\n",
    "            c += 1\n",
    "        for i in self.freqs:\n",
    "            for j in self.phases:\n",
    "                print(\"Coef de sinusoide con frecuencia {} y fase {}:\\n{}\".format(i, j, self.coefs[c]))\n",
    "                c += 1\n",
    "                \n",
    "    def fit(self, train_set):\n",
    "        arrays = self.get_x_vals(train_set)\n",
    "        A = np.stack(arrays)\n",
    "        self.coefs = np.linalg.solve(A.T@A, A.T@train_set)\n",
    "    \n",
    "    def pred(self, pred_set):\n",
    "        arrays = self.get_x_vals(pred_set)\n",
    "        full_A = np.stack(arrays)        \n",
    "        return full_A@self.coefs \n",
    "    \n",
    "lpr = lsqPredictor(phases, daily_freqs, max_grade)\n",
    "lpr.fit(train_delays)\n",
    "lpr.print_coefs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"dl_pred\" in df:\n",
    "    del df[\"dl_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_delays = df[\"ArrDelay\"]\n",
    "\n",
    "df[\"dl_pred\"] = lpr.pred(train_test_delays) \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.plot(x=\"date\", y=[\"DepDelay\", \"dl_pred\"], figsize=(16,5))\n",
    "\n",
    "def plot_df(df1, df2, train_limit_axis, unit_str):\n",
    "    plt.figure(figsize=(16,5))\n",
    "    plt.xlabel('Predicción para el i-ésimo {}'.format(unit_str))\n",
    "\n",
    "    df2 = df2[df2.index % 20 == 0] \n",
    "    df1 = df1[df1.index % 20 == 0] \n",
    "    \n",
    "    ax1 = df1.dl_pred.plot(color='orange', grid=True, label='pred delay')\n",
    "    df2.ArrDelay.plot(color='blue', grid=True, secondary_y=False, label='real delay', ax=ax1)\n",
    "\n",
    "    xticks = ax1.xaxis.get_major_ticks()\n",
    "    plt.axvline(x=train_limit_axis, color=\"green\")\n",
    "    plt.show()\n",
    "\n",
    "df_full = pd.read_csv(tmp_dir+\"daily/full.csv\")\n",
    "df_full['date'] = pd.to_datetime(df_full['date'], errors='coerce')\n",
    "plot_df(df, df_full, len(train_delays), \"dia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "math.sqrt(mean_squared_error(df.loc[df[\"date\"].dt.year>year_train_limit].dl_pred, df_full.loc[df_full[\"date\"].dt.year>year_train_limit].ArrDelay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mensual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(tmp_dir+\"monthly/cut.csv\")\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "df.sort_values(by=\"date\")\n",
    "year_train_limit = 2002\n",
    "lower_year_train_limit = 1994\n",
    "train_delays = df.loc[(df[\"date\"].dt.year < year_train_limit) & \\\n",
    "                      (df[\"date\"].dt.year > lower_year_train_limit)][\"ArrDelay\"]\n",
    "\n",
    "lpr = lsqPredictor(phases, monthly_freqs, max_grade)\n",
    "lpr.fit(train_delays)\n",
    "lpr.print_coefs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"dl_pred\" in df:\n",
    "    del df[\"dl_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_delays = df[\"ArrDelay\"]\n",
    "\n",
    "df[\"dl_pred\"] = lpr.pred(train_test_delays) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(tmp_dir+\"monthly/full.csv\")\n",
    "df_full['date'] = pd.to_datetime(df_full['date'], errors='coerce')\n",
    "plot_df(df, df_full, len(train_delays), \"mes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sqrt(mean_squared_error(df.loc[df[\"date\"].dt.year>year_train_limit].dl_pred, df_full.loc[df_full[\"date\"].dt.year>year_train_limit].ArrDelay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BORRAR ARCHIVOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#borrar aux de años\n",
    "for filename in os.listdir(tmp_dir):\n",
    "    if fnmatch.fnmatch(filename, '*.csv') and filename != \"merged.csv\":\n",
    "        os.remove(tmp_dir+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#borrar merged\n",
    "os.remove(tmp_dir+\"merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#borrar tmp\n",
    "shutil.rmtree(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
